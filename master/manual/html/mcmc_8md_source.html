<!-- HTML header for doxygen 1.8.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <!-- For Mobile Devices -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
        <meta name="generator" content="Doxygen 1.8.11"/>
        <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
        <title>BAT manual: mcmc.md Source File</title>
        <!--<link href="tabs.css" rel="stylesheet" type="text/css"/>-->
        <script type="text/javascript" src="dynsections.js"></script>
        <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
MathJax.Hub.Config({
    TeX: {
        Macros: {
            cond: ["{\\,|\\,}"],
            diag: ["{\\mbox{diag}}"],
            matsig: ["{\\boldsymbol{\\Sigma}}"],
            rmdx: ["{\\mbox{d}#1\\,}",1],
            scath: ["{\\theta}"],
            vecmu: ["{\\boldsymbol{\\mu}}"],
            vecth: ["{\\boldsymbol{\\theta}}"],
            order: ["{\\mathcal{O}(#1)}",1],
        }
    }
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML/MathJax.js"></script>
        <link href="doxygen.css" rel="stylesheet" type="text/css" />
        <link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
        <link href='https://fonts.googleapis.com/css?family=Roboto+Slab' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
        <script type="text/javascript" src="doxy-boot.js"></script>
    </head>
    <body>
        <nav class="navbar navbar-default" role="navigation">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand">BAT manual 1.0.0</a>
                </div>
            </div>
        </nav>
        <div id="top"><!-- do not remove this div, it is closed by doxygen! -->
            <div class="content" id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-sm-12 panel " style="padding-bottom: 15px;">
                            <div style="margin-bottom: 15px;">
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Overview</span></a></li>
      <li><a href="pages.html"><span>Chapters</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">mcmc.md</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;Markov chain Monte Carlo {#cha-mcmc}</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;=======================</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;[TOC]</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;# Motivation {#sec-mcmc-motiv}</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;Among the integration methods introduced in @ref cha-integration, the Monte Carlo method is the most powerful one in high dimensions. The term Monte Carlo is used as a synonym for the use of pseudo-random numbers. Markov chains are a particular class of Monte Carlo algorithms designed to generate correlated samples from an arbitrary distribution. The central workhorse in BAT is an adaptive Markov chain Monte Carlo (MCMC) implementation based on the Metropolis algorithm. It allows users to marginalize a posterior without requiring manual tuning of algorithm parameters. In complicated cases, tweaking the parameters can substantially increase the efficiency, so BAT gives users full access to all tuning parameters.</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;# Foundations {#sec-mcmc-foundations}</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;## Monte Carlo integration {#sec-mcmc-integration}</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;We begin with the *fundamental Monte Carlo* principle. Suppose we have a posterior</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;probability density \f$P(\vecth|D)\f$, often called the *target*</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;density, and an arbitrary function \f$f(\vecth)\f$ with finite</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;expectation value under \f$P\f$</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;\f{align}{</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;    \label{eq:mc-expect}</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;    E_P[ f ] = \int \rmdx{ \vecth} P(\vecth|D) f(\vecth) &lt; \infty .</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;\f}</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;Then a</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;set of draws \f$\{ \vecth_i:i=1 \dots N \}\f$ from the density \f$P\f$, that is \f$\vecth_i \sim P\f$, is</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;enough to estimate the expectation value. Specifically, the integral</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;can be replaced by the estimator (distinguished by the symbol</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;\f$\widehat{\phantom{a}}\f$)</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;\f{align}{ \label{eq:mc-expect-discrete} \boxed{</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;\widehat{E_P[f]} \approx \frac{1}{N} \sum_{i=1}^{N} f(\vecth_i), \;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;\vecth \sim P  }</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;\f}</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;As \f$N \to \infty\f$, the estimate</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;converges almost surely at a rate \f$\propto 1/\sqrt{N}\f$</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;by the strong law of large numbers if \f$\int \rmdx{ \vecth}</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;P(\vecth|D) f^2(\vecth) &lt; \infty\f$ @cite Casella:2004 . This is true for independent samples from the target but also for correlated samples. The only thing that changes is the increased variance of the estimator due to correlation.</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;@anchor mcmc-histogram</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;@imageSize{histogram.svg,width:300px;,Histogram approximation to the 1D marginal.}</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;@image latex histogram.pdf &quot;Histogram approximation to the 1D marginal.&quot; width=0.3\textwidth</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;How does this @latexonly Eq.~\ref{eq:mc-expect-discrete}@endlatexonly</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;relate to Bayesian inference? Upon applying Bayes’ theorem to</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;real-life problems, one usually has to marginalize over several</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;parameters, and this can usually not be done analytically, hence one</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;has to resort to numerical techniques. In low dimensions, say \f$d \le</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;2\f$, quadrature and other grid-based methods are fast and accurate,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;but as \f$d\f$ increases, these methods generically suffer from the</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;*curse of dimensionality*. The number of function evaluations grows</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;exponentially as \f$\order{m^d}\f$, where \f$m\f$ is the number of</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;grid points in one dimension. Though less accurate in few dimensions,</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;Monte Carlo — i.e., random-number based — methods are the first choice</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;in \f$d \gtrsim 3\f$ because the computational complexity is (at least</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;in principle) independent of \f$d\f$. Which function \f$f\f$ is of</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;interest to us? For example when integrating over all but the first</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;dimension of \f$\vecth\f$, the marginal posterior probability</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;that \f$\theta_1\f$ is in \f$[a,b)\f$ can be estimated as</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;\f[</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;\label{eq:disc-marg} P(a \le \theta_1 \le b|D) \approx \frac{1}{N}</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;\sum_{i=1}^{N} \mathbf{1}_{\theta_1 \in [a,b)} (\vecth_i) \, \f]</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;with the *indicator function*</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;\f[ \label{eq:indicator-fct}</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;\mathbf{1}_{\theta_1 \in [a,b)} (\vecth) = \begin{cases} 1, \theta_1</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;\in [a,b) \\ 0, {\rm else} \end{cases}</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;\f]</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;This follows immediately from the Monte Carlo principle with</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;\f$f(\vecth) = \mathbf{1}_{\theta_1 \in [a,b)}(\vecth)\f$. The major</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;simplification arises as we perform the integral over \f$d-1\f$</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;dimensions simply by ignoring these dimensions in the indicator</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;function. If the parameter range of \f$\theta_1\f$ is partitioned into</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;bins, then the above holds in every bin, and defines the histogram</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;approximation to \f$P(\theta_1|D)\f$. In exact analogy, the 2D</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;histogram approximation is computed from the samples for 2D bins in</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;the indicator function. For understanding and presenting the results</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;of Bayesian parameter inference, the set of 1D and 2D marginal</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;distributions is the primary goal. Given samples from the full</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;posterior, we have immediate access to *all* marginal distributions at</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;once; i.e., there is no need for separate integration to obtain for</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;example \f$P(\theta_1|D)\f$ and \f$P(\theta_2|D)\f$. This is a major</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;benefit of the Monte Carlo method in conducting Bayesian inference.</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;## Metropolis algorithm {#sec-mcmc-metropolis}</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;The key ingredient in BAT is an implementation of the Metropolis</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;algorithm to create a Markov chain; i.e. a sequence of (correlated)</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;samples from the posterior. We use the shorthand MCMC for Markov chain</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;Monte Carlo.</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;Efficient MCMC algorithms are the topic of past and current</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;research. This section is a concise overview of the general idea and</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;the algorithms available in BAT. For a broader overview, we refer the</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;reader to the abundant literature; e.g.,</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;@cite Casella:2004</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;@cite brooks2011handbook .</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;In BAT, there are several variants of the random-walk Metropolis Hastings algorithm available. The basic idea is captured in the @ref random-walk-2D &quot;2D example plot&quot;. Given an initial point \f$\vecth_0\f$, the Metropolis algorithm produces a sample in each iteration \f$t=1 \dots N \f$ as follows:</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;* Propose a new point \f$\tilde{\vecth}\f$</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;* Generate a number u from the uniform distribution on [0,1]</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;* Set \f$\vecth_{t} = \tilde{\vecth}\f$ if \f$ u &lt; \frac{P(\tilde{\vecth} \cond D)}{P(\vecth_{t-1} \cond D)}\f$</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;* Else stay, \f$\vecth_t = \vecth_{t-1}\f$</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;@anchor random-walk-2D</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;@image html random-walk.png &quot;2D random walk with the Metropolis algorithm.&quot;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;@image latex random-walk.pdf &quot;2D random walk with the Metropolis algorithm.&quot; width=0.5\textwidth</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;In the example plot, the chain begins in the lower left</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;corner. Rejected moves are indicated by the dashed arrow, accepted</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;moves are indicated by the solid arrow. The circled number is the</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;number of iterations the chain stays at a given point \f$\vecth =</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;(\theta_1, \theta_2)\f$.</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;In each iteration \f$t\f$, one updates the estimate of the 1D marginal</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;distribution \f$P(\theta_1 | D)\f$ by adding the first coordinate of</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;\f$\vecth_t\f$ to a histogram. Repeat this for all other coordinates to update</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;the other \f$(d-1)\f$ 1D marginals. And redo it for all pairs of coordinates to</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;estimate the 2D marginals.</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;As a concrete example, suppose the chain has 5 iterations in 2D:</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;\f$t\f$ | \f$\vecth_t\f$</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;:----- | :----------</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;1       | \f$(1.1, 2.3)\f$</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;2       | \f$(1.1, 2.3)\f$</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;3       | \f$(3.8, 1.8)\f$</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;4       | \f$(2.4, 5.2)\f$</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;5       | \f$(1.8, 4.2)\f$</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;Let us choose a histogram to approximate the 1D marginal posterior for</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;\f$\theta_1\f$ with five bins from \f$[n, n+1)\f$ for \f$n=0 \dots 4\f$ such</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;that the right edge of the bin is not included. Up to \f$t=5\f$, the histogram</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;is</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160; \f$n\f$| weight</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;:----- | :----------</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;0       | 0</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;1       | 3</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;2       | 1</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;3       | 1</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;4       | 0</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;In the end, we usually normalize the histogram so it estimates a proper</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;probability density that integrates to 1.</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;## Convergence {#sec-mcmc-convergence}</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;Since samples are not independent, the initial point has some effect on Markov</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;chain output. The asymptotic results guarantee that, under certain conditions</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;(see @cite Casella:2004 or @cite brooks2011handbook) a chain of infinite length</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;is independent of the initial point. In practice, we can only generate a finite</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;number of points so a decision has to be made when the chain has run long</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;enough. One helpful criterion is to run multiple chains from different initial</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;positions and to declare convergence if the chains mixed; i.e. explore the same</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;region of parameter space. Then the chains have forgotten their initial point.</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;Non-convergence is a problem that can have many causes including simple bugs in</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;implementing the posterior. But there are properly implemented posteriors for</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;which a Markov chain has difficulties to explore the parameter space</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;efficiently, for example because of strong correlation, degeneracies, or</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;multiple well separated modes.</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;# Implementation in BAT {#sec-mcmc-impl}</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;Implementing the Metropolis algorithm, one has to decide on how to</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;propose a new point based on the current point, that is one needs the</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;*proposal function* \f$q(\tilde{\vecth} \cond \vecth_t, \xi)\f$ with adjustable parameters</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;\f$\xi\f$. The main difference between MCMC algorithms is typically given</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;by different choices of \f$q\f$. The Metropolis algorithm doesn&#39;t specify</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;which \f$q\f$ to choose, so we can and have to select a function \f$q\f$ and</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;tune \f$\xi\f$ according to our needs.</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;In BAT, the proposal is *symmetric* around the current point</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;\f{align}{</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;  q(\tilde{\vecth} \cond \vecth_t, \xi) = q(\vecth_t \cond \tilde{\vecth}, \xi).</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;\f}</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;The Markov property implies that the proposal may only depend on the current</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;point \f$\vecth_t\f$ and not on any previous point. If the value of \f$\xi\f$ is</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;set based on a past sequence of iterations of the chain, we need two stages of</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;sampling in BAT, the *prerun* and the *main run*. In the prerun, the chain is</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;run and periodically \f$\xi\f$ is updated based on the past iterations. In</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;contrast, \f$\xi\f$ is kept fixed in the main run to have a proper Markov chain.</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;## Proposal functions {#sec-mcmc-proposal}</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;BAT offers two kinds of proposal function termed *factorized* and</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;*multivariate*. The general form is either a Gaussian or Student&#39;s t</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;distribution. In the factorized case, the joint distribution is a product of 1D</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;distributions. In the multivariate case, a dense covariance matrix is used that</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;allows correlated proposals. In either case, the default is Student&#39;s t</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;distribution with one degree of freedom (dof); i.e., a Cauchy distribution.</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;Select the proposal like this:</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;@code{.cpp}</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;m.SetProposeMultivariate(true);</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;m.SetProposalFunctionDof(5); // Student&#39;s t with 5 degrees of freedom</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;m.SetProposalFunctionDof(-1); // Gaussian</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;@endcode</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;### Multivariate proposal {#sec-mcmc-multivariate}</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;@since Introduced and set as the default in v1.0</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;Changing all \f$d\f$ parameters at once within one iteration is an</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;all-or-nothing approach. If the proposed move is accepted, all</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;parameters have changed for the price of a single evaluation of the</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;posterior. If the move is rejected, the new point is identical to the</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;old point and the chain does not explore the parameter space.</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;We implement the adaptive algorithm by Haario et al. @cite Haario:2001,</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;@cite Wraith:2009if. In brief, the proposal is a multivariate Gaussian or Student&#39;s t</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;distribution whose covariance is learned from the covariance of samples in the</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;prerun. An overall scale factor is tuned to force the acceptance rate into a</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;certain range.</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;the multivariate normal distribution</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;\f{equation}{</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;  \label{eq:multivar-normal}</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;  \mathcal{N}(\vecth | \vecmu, \matsig) = \frac{1}{(2\pi)^{d/2}} \left|\matsig\right|^{-1/2}</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;  \exp(-\frac{1}{2} (\vecth - \vecmu)^T \matsig^{-1} (\vecth - \vecmu) )</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;\f}</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;or the multivariate Student&#39;s t distribution</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;\f{equation}{</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;  \label{eq:multivar-student}</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;  \mathcal{T}</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;  (\vecth | \vecmu, \matsig, \nu)  =</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;  \frac{\Gamma( (\nu + d) / 2 )}{\Gamma(\nu / 2) (\pi \nu)^{d/2}} \left|\matsig\right|^{-1/2}</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;  ( 1 + \frac{1}{\nu}(\vecth - \vecmu)^T \matsig^{-1} (\vecth - \vecmu) )^{-(\nu + d)/2}</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;\f}</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;can adapt in such a way as to efficiently generate samples from essentially any</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;smooth, unimodal distribution. The parameter \f$\nu\f$, the degree of freedom,</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;controls the ``fatness&#39;&#39; of the tails of \f$\mathcal{T}\f$; the covariance of</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;\f$\mathcal{T}\f$ is related to the scale matrix \f$\matsig\f$ as \f$\frac{\nu}{\nu - 2}</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;\times \matsig\f$ for \f$\nu &gt; 2\f$, while \f$\matsig\f$ is the covariance of</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;\f$\mathcal{N}\f$. Hence for finite \f$\nu\f$, \f$\mathcal{T}\f$ has fatter tails than</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;\f$\mathcal{N}\f$, and for \f$\nu \to \infty\f$, \f$\mathcal{T}(\vecth | \vecmu, \matsig,</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;\nu) \to \mathcal{N}(\vecth | \vecmu, \matsig)\f$.</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;Before delving into the details, let us clarify at least qualitatively what we</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;mean by an efficient proposal.  Our requirements are</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;* that it allow to sample from the entire target support in finite time,</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;* that it resolve small and large scale features of the target,</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;* and that it lead to a Markov chain quickly reaching the asymptotic regime.</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;An important characteristic of Markov chains is the acceptance rate</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;\f$\alpha\f$, the ratio of accepted proposal points versus the total length of the</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;chain. We argue that there exists an optimal \f$\alpha\f$ for a given target and</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;proposal. If \f$\alpha = 0\f$, the chain is stuck and does not explore the</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;state space at all. On the contrary, suppose \f$\alpha = 1\f$ and the target</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;distribution is not globally uniform, then the chain explores only a tiny volume</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;where the target distribution changes very little. So for some \f$\alpha \in (0,1)\f$,</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;the chains explore the state space well.</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;How should the proposal function be adapted? After a chunk of \f$N_{\rm</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;update}\f$ iterations, we change two things. First, in order to propose points</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;according to the correlation present in the target density, the proposal scale</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;matrix \f$\matsig\f$ is updated based on the sample covariance of the last</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;\f$n\f$ iterations. Second, \f$\matsig\f$ is multiplied with a scale factor</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;\f$c\f$ that governs the range of the proposal. \f$c\f$ is tuned to force the</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;acceptance rate to lie in a region of \f$0.15 \le \alpha \le 0.35\f$. The</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;\f$\alpha\f$ range is based on empirical evidence and the following fact: for a</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;multivariate normal proposal function, the optimal \f$\alpha\f$ for a normal</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;target density is \f$0.234\f$, and the optimal scale factor is \f$c =</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;2.38^2/d\f$ as the dimensionality \f$d\f$ approaches \f$\infty\f$ and the chain</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;is in the stationary regime @cite Roberts:1997 . We fix the proposal after a</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;certain number of adaptations, and then collect samples for the final inference</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;step. However, if the Gaussian proposal function is adapted indefinitely, the</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;Markov property is lost, but the chain and the empirical averages of the</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;integrals @latexonly represented by Eq.~\ref{eq:mc-expect}@endlatexonly still</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;converge under mild conditions @cite Haario:2001.</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;The efficiency can be enhanced significantly with good initial guesses for \f$c\f$</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;and \f$\matsig\f$. We use a subscript \f$t\f$ to denote the status after \f$t\f$ updates.</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;It is often possible to extract an estimate of the target covariance by running</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;a mode finder like MINUIT that yields the covariance matrix at</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;the mode as a by product of optimization. In the case of a degenerate target</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;density, MINUIT necessarily fails, as the gradient is not defined. In such</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;cases, one can still provide an estimate as</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;\f{equation}{</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;  \label{eq:sigma-initial}</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;  \matsig^0 = \diag ( \sigma_1^2, \sigma_2^2, \dots, \sigma_d^2)</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;\f}</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;where \f$\sigma_i^2\f$ is the prior variance of the \f$i\f$-th parameter.  The updated value of</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;\f$\matsig\f$ in step \f$t\f$ is</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;\f{equation}{</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;  \label{eq:sigma-update}</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;  \matsig^t = (1 - a^t) \matsig^{t-1} + a^t \boldsymbol{S}^t</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;\f}</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;where \f$\boldsymbol{S}^t\f$ is the sample covariance of the points in chunk \f$t\f$ and</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;its element in row \f$m\f$ and column \f$n\f$ is computed as</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;\f{equation}{</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;  \label{eq:sample-cov}</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;  (\boldsymbol{S}^t)_{mn} = \frac{1}{N_{\rm update}-1} \sum_{i=(t-1) \cdot N_{\rm update}}^{t \cdot N_{\rm update}}</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;  ( (\vecth^i)_m -  \widehat{E_P[(\vecth)_m]} ) ((\vecth^i)_n - \widehat{E_P[(\vecth)_n]} )</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;\f}</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;The weight \f$a^t = 1/t^{\lambda}, \lambda \in [0,1]\f$ is chosen to make for a</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;smooth transition from the initial guess to the eventual target covariance, the</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;implied cooling is needed for the ergodicity of the chain if the proposal is not</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;fixed at some point @cite Haario:2001. One uses a fixed value of \f$\lambda\f$,</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;and the particular value has an effect on the efficiency, but the effect is</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;generally not dramatic; in this work, we set \f$\lambda=0.5\f$</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;@cite Wraith:2009if.</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;We adjust the scale factor \f$c\f$ as described in the pseudocode shown below.</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;The introduction of a minimum and maximum scale factor is a safeguard against</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;bugs in the implementation. The only example we can think of that would result</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;in large scale factors is that of sampling from a uniform distribution over a</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;very large volume. All proposed points would be in the volume, and accepted, so</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;\f$\alpha \equiv 1\f$, irrespective of \f$c\f$. All other cases that we</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;encountered where \f$c &gt; c_{max}\f$ hinted at errors in the code that performs</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;the update of the proposal.</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;@code{.cpp}</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;// default values</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;αmin = 0.15; αmax = 0.35;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;cmin = 1e-5; cmax = 100;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;β = 1.5;</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;// single update of the covariance scale factor</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;if (α &gt; αmax &amp;&amp; c &lt; cmax) {</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;  c *= β * c</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;} else if (α &lt; αmin &amp;&amp; c &gt; cmin) {</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;  c /= β</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;}</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;@endcode</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;@see `BCEngineMCMC::SetMultivariateCovarianceUpdateLambda`, `BCEngineMCMC::SetMultivariateEpsilon`, `BCEngineMCMC::SetMultivariateScaleMultiplier`</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;### Factorized proposal {#sec-mcmc-factorized}</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;@since Factorized was the default and only choice prior to v1.0 and continues to be available using `BCEngineMCMC::SetProposeMultivariate(false)`</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;The factorized proposal in \f$d\f$ dimensions is a product of 1D proposals.</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;We sequentially vary one parameter at a time and complete</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;one iteration of the chain once a new point has been proposed in *every*</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;direction. This means the chain attempts to perform a sequence of</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;axis-aligned moves in one iteration.</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;Each 1D proposal is a Cauchy or Breit-Wigner function centered on the</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;current point. The scale parameter is adapted in the prerun to achieve</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;an acceptance rate in a given range that can be adjusted by the</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;user. Note that there is a separate scale parameter in every dimension.</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;This means the posterior is called \f$d\f$ times in every iteration. Since the</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;acceptance rate is typically different from zero or one, the factorized proposal</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;typically generates a new point in every iteration that differs from the</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;previous point in some but not all dimensions.</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;### Comparison {#sec-mcmc-proposal-comparison}</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;Comparing the factorized proposal to the multivariate proposal, we</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;generally recommend the multivariate for most purposes.</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;Use the factorized proposal if you can speed up the computation of the</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;posterior if you know that some parameters did not change. This can be</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;useful if the computation is expensive if some but not all</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;parameters change.</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;## Prerun {#sec-mcmc-prerun}</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;During the prerun, the proposal is updated. BAT considers three criteria to decide when to end the prerun. The prerun takes some minimum number of iterations and is stopped no matter what if the maximum number of prerun iterations is reached. In between, the prerun terminates if the efficiency and the \f$R\f$ value checks are ok. To perform the prerun manually, do</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;@code{.cpp}</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;m.MetropolisPreRun();</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;@endcode</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;In most cases this is not needed, because `BCModel::MarginalizeAll` calls</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;`BCEngineMCMC::Metropolis`, which will take care of the prerun and the main run</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;and all the data handling associated with it. To force a prerun to be run again, perhaps after it failed and some settings have been adjusted, do:</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;@code{.cpp}</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;m.SetFlagPreRun(true);</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;m.MarginalizeAll();</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;@endcode</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;### Efficiency {#sec-mcmc-eff}</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;The *efficiency*, or acceptance rate, is the ratio  of the accepted over the total number proposal moves. A small efficiency means the chain rarely moves but may then make a large move. A large efficiency means the chain explores well locally but may take a long time to explore the entire region of high probability. Optimality results exists only for very special cases: Roberts and Rosenthal showed that for a Gaussian target with \f$d\f$ independent components and a Gaussian proposal, the optimal target efficiency is 23.4 % for \f$d \geq 5\f$ is  but should be larger for small \f$d\f$; e.g., 44 % is best in one dimension @cite rosenthal2011optimal . Based on our experience, we use a default range for the efficiency as \f$[0.15, 0.35]\f$.</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;@see `BCEngineMCMC::SetMinimumEfficiency`, `BCEngineMCMC::SetMaximumEfficiency`</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;### R value {#sec-mcmc-Rvalue}</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;The *R value* @cite Gelman:1992 by Gelman and Rubin quantifies the</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;estimated scale reduction of the uncertainty of an expectation value</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;estimated with the samples if the chain were run infinitely</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;long. Informally, it compares the mean and variance of the expectation</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;value for a single chain with the corresponding results of multiple</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;chains. If the chains mix despite different initial values, then we</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;assume that they are independent of the initial value, the burn-in is</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;over, and the samples produce reliable estimates of quantities of</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;interest. For a single chain, the \f$R\f$ value cannot be computed.</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;In BAT, we monitor the expectation value of each parameter and declare</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;convergence if all R values are below a threshold. Note that the R</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;values are estimated from batches of samples, and they usually</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;decrease with more iterations but they may also increase, which</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;usually is a clear indication that the chains do not mix, perhaps due</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;to multiple modes that trap the chains.</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;@see `BCEngineMCMC::SetRValueParametersCriterion` Set the maximum allowed \f$R\f$ value for all parameters. By defition, \f$R\f$ cannot go below 1 except for numerical inaccuracy. **Default: 1.1**</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;@see `BCEngineMCMC::SetCorrectRValueForSamplingVariability` The strict definition of \f$R\f$ corrects the sampling variability due finite batch size. **Default: false**</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;@see `BCEngineMCMC::GetRValueParameters`  \f$R\f$ values are computed during the prerun and they can be retrieved but not set.</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;### Prerun length {#sec-mcmc-prerun-length}</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;Defining convergence automatically based on the efficiency or the \f$R\f$ value is convenient may be too conservative if the user knows a good initial value, a good proposal, etc. For more control the minimum and maximum length of the prerun can be set, too.</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;@see `BCEngineMCMC::SetNIterationsPreRunMin`, `BCEngineMCMC::SetNIterationsPreRunMax`</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;@see `BCEngineMCMC::SetNIterationsPreRunCheck` sets the number of iterations between checks</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;If desired, the statistics can be cleared to remove the effect of a bad initial point with `BCEngineMCMC::SetPreRunCheckClear` after some set of iterations</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;&lt;!-- @todo A flow diagram might help --&gt;</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;For the user&#39;s convenience, multiple settings related to precision of the Markov</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;chain can be set at once using `BCEngineMCMC::SetPrecision`. The default setting</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;is `m.SetPrecision(BCEngineMCMC::kMedium)`.</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;## Main run {#sec-mcmc-main-run}</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;In the main run, the proposal is held fixed and each chain is run for `BCEngineMCMC::GetNIterationsRun()` iterations.</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;@see `BCEngineMCMC::SetNIterationsRun`</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;To reduce the correlation between samples, a lag can be introduced to take only every 10th element with `BCEngineMCMC::SetNLag`.</div></div><!-- fragment --></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.8-->
<!-- start footer part -->
</div>
</div>
</div>
</div>
</div>
<!-- <hr class="footer"/><address class="footer"><small> -->
<!-- Generated on Fri May 18 2018 12:43:13 for BAT manual by &#160;<a href="http://www.doxygen.org/index.html"> -->
<!-- <img class="footer" src="doxygen.png" alt="doxygen"/> -->
<!-- </a> 1.8.11 -->
<!-- </small></address> -->
</body>
</html>
